
# Commande pour lancer le script (se placer dans le dossier):
# snakemake -s Snakefile_MergeDonneurs --use-conda --reason --cores 12

from snakemake.io import expand
from collections import defaultdict
from functools import partial

SAMPLE = ['2DG_03h_D1-D2-D3','2DG_06h_D1-D2-D3','2DG_12h_D1-D2-D3','2DG_24h_D1-D2-D3','AOA_03h_D1-D2-D3','AOA_06h_D1-D2-D3','AOA_12h_D1-D2-D3','AOA_24h_D1-D2-D3','DON_03h_D1-D2-D3','DON_06h_D1-D2-D3','DON_12h_D1-D2-D3','DON_24h_D1-D2-D3','MP_03h_D1-D2-D3','MP_06h_D1-D2-D3','MP_12h_D1-D2-D3','MP_24h_D1-D2-D3-D5-D6','VPA_24h_D4-D5-D6', 'aK_24h_D4-D5-D6']

# LINK_TAB = {}
# SAMPLE = defaultdict(partial(defaultdict, dict))
#
# import csv
# with open('link_tab.csv', mode='r') as file:
# 	reader = csv.reader(file)
# 	next(reader, None)  # skip the headers
# 	for row in reader:
# 		use, condition, time, donor, manip, raw_file = row
# 		if use == "false":
# 			continue
# 		SAMPLE[condition][time][donor] = raw_file
#
# def list_sample():
# 	result = []
# 	for condition, times in SAMPLE.items():
# 		for time, donors in times.items():
# 			for donor, file in donors.items():
# 				result.append("_".join((condition, time, donor)))
# 	return result
#
# wildcard_constraints:
# 	donor="D\d+",
# 	donors="D\d+(,D\d+)+",
# 	sample="\w+_\d{2}h_D\d+"

rule all :
	input :
		### Test bloc 2 ###
		# Files
		# expand("D_results_merged/downsampled_bam/{sample}_downsampled.bam.bai", sample = SAMPLE),
		# expand("D_results_merged/genomic_ranges/static_peaks/{sample}_peaks.gr.rds", sample = SAMPLE),
		# expand("D_results_merged/macs2_output/{sample}.threshold.broadPeak", sample = SAMPLE),
		# expand("D_results_merged/genomic_ranges/static_peaks/{sample}.threshold.gr.rds", sample = SAMPLE),
		# # Reports
		"D_results_merged/reports/qc_report.csv",
		# "D_results_merged/reports/nbreads_report.csv",
		# "D_results_merged/reports/nbpeaks_report.csv",
		# "D_results_merged/reports/nbreads_per_peak_report.csv",
		# Graph
		# "D_results_merged/reports/qc_report_plot_hist_manip-QCP_nb_mapped.png",
		# "D_results_merged/reports/qc_report_plot_hist_manip-QCP_pct_mapped.png",
		# "D_results_merged/reports/nbreads_report_plot_hist_manip-nbreads_before_downsampling.png",
		# "D_results_merged/reports/nbreads_report_plot_hist_manip-nbreads_after_downsampling.png",
		# "D_results_merged/reports/nbpeaks_report_plot_hist_manip-lost_percentage.png",
		# "D_results_merged/reports/nbpeaks_report_plot_hist_manip-nbpeaks_before_threshold.png",
		# "D_results_merged/reports/nbpeaks_report_plot_hist_manip-nbpeaks_after_threshold.png",
		# "D_results_merged/reports/nbpeaks_report_plot_line_cond-nbpeaks_before_threshold.png",
		# "D_results_merged/reports/nbpeaks_report_plot_line_cond-nbpeaks_after_threshold.png",
		# "D_results_merged/reports/nbpeaks_report_plot_hist_manip-lost_percentage.png",
		# "D_results_merged/reports/nbreads_per_peak_report_plot_read_graph-nbreads.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_report_plot_chrom_single-Peak_count.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_report_plot_chrom_multi-Peak_count.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_report_plot_chrom_single-Peak_percentage.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_report_plot_chrom_multi-Peak_percentage.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_threshold_report_plot_chrom_single-Peak_count.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_threshold_report_plot_chrom_multi-Peak_count.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_threshold_report_plot_chrom_single-Peak_percentage.pdf",
		# "D_results_merged/reports/nbpeaks_per_chromosome_threshold_report_plot_chrom_multi-Peak_percentage.pdf"


#*******************************************************************************************************************************************************
#*** Bloc 2 : Individual study and QC of each sample
#*******************************************************************************************************************************************************

# Fonctionne mais très très lent car pas de parallélisation + problème quand on appelle tout le snakefile mais fonctionne quand on appelle juste la règle
rule merge_donors :
	input :
		csv = "link_tab.csv",
		dir_bam = "A_raw_data/bam_files"
	output : "D_results_merged/bam_files_merged/{condition}_{time}_{list_donors}.bam"
	params : output_dir = "D_results_merged/bam_files_merged/"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/mergeBamFiles.R --output_dir {params.output_dir} {input.csv} {input.dir_bam} """

# ====================
# Generic BAM analysis
# ====================

rule bam_qc :
	input : "{file}.bam"
	output : "{file}.bam.qc"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ samtools flagstat -O tsv {input} > {output} """

rule bam_nbreads :
	input : "{file}.bam"
	output : "{file}.bam.nbreads"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ samtools view -c {input} > {output} """

rule bam_indexing :
	input : "{file}.bam"
	output : "{file}.bam.bai"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ samtools index {input} > {output} """

# ================
# BAM downsampling
# ================

# Compute the downsampling value to equalize the number of reads all bam files
# params.output is used to persist if the downsampling value does not change
#   It is updated only if the value changed
#   So the downsampling is redone only if the value changed
checkpoint bam_downsampling_value :
	input : expand("D_results_merged/bam_files_merged/{sample}.bam.nbreads", sample = SAMPLE)
	output : temp("D_results_merged/downsampled_bam/downsampling_value_new")
	params : output = "D_results_merged/downsampled_bam/downsampling_value"
	shell : """
        min=$(cat {input} | sort -n | head -1)
        echo "Downsampling value = $min"
        if [ -f {params.output} ] && [ "$(cat {params.output})" = "$min" ]; then
          echo "Unchanged"
        else
          echo "Changed"
          echo "$min" > {params.output}
        fi
        echo "$min" > {output}
        """

def bam_downsampling_input(wildcards):
	checkpoints.bam_downsampling_value.get()
	return {
		'bam': "D_results_merged/bam_files_merged/{sample}.bam",
		'nbreads': "D_results_merged/bam_files_merged/{sample}.bam.nbreads",
		'downsampling_value': rules.bam_downsampling_value.params.output
	}

# Downsample bam file to the downsampling value in the downsampling_value file
rule bam_downsampling :
	input : unpack(bam_downsampling_input)
	output : "D_results_merged/downsampled_bam/{sample}_downsampled.bam"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """
        count=$(cat {input.nbreads})
        min=$(cat {input.downsampling_value})
        echo "Downsampling value = $min"
        downsampling_ratio=$(echo "$min/$count" | bc -l)
        samtools view -s 1$downsampling_ratio -b {input.bam} > {output}
        """

#=============
# Peak analysis
#=============

rule peak_calling :
	input : "D_results_merged/downsampled_bam/{sample}_downsampled.bam"
	output : "D_results_merged/macs2_output/{sample}_peaks.broadPeak"
	params :
		prefix = "{sample}",
		macs2_output_dir = "D_results_merged/macs2_output"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ macs2 callpeak -t {input} -n {params.prefix} --outdir {params.macs2_output_dir} -f BAMPE -g hs -B --broad --broad-cutoff 0.1 """

rule broadPeak_to_csv :
	wildcard_constraints :
		name="_peaks|.threshold"
	input : "D_results_merged/macs2_output/{sample}{name}.broadPeak"
	output : "D_results_merged/macs2_output/{sample}{name}.df.csv"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/broadPeak_to_csv.R {input} {output}"""

rule readcount_matrix :
	input :
		csv = "D_results_merged/macs2_output/{sample}_peaks.df.csv",
		bam = "D_results_merged/downsampled_bam/{sample}_downsampled.bam"
	output : "D_results_merged/macs2_output/{sample}.readcount.csv"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/peaks_featureCounts.R --output_csv {output} {input.csv} {input.bam}"""

rule qc_peaks_threshold :
	input :
		peaks_broadPeak = "D_results_merged/macs2_output/{sample}_peaks.broadPeak",
		readcount_matrix = "D_results_merged/macs2_output/{sample}.readcount.csv"
	output : "D_results_merged/macs2_output/{sample}.threshold.broadPeak"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/peaks_filter.R {input.peaks_broadPeak} {input.readcount_matrix} {output} """

rule create_grange :
	input : "D_results_merged/macs2_output/{name}.df.csv"
	output : "D_results_merged/genomic_ranges/static_peaks/{name}.gr.rds"
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/GRanges.R from_csv -o {output} {input} """

# =======
# Reports and QC plots
# =======

# Report on quality of original bam files
rule qc_report :
	input : expand("D_results_merged/bam_files_merged/{sample}.bam.qc", sample = SAMPLE)
	output : "D_results_merged/reports/qc_report.csv"
	params : sample =  SAMPLE
	shell : """
        sample=({params.sample})
        qc_files=({input})
        echo "condition;time;QCP_nb_read;QCF_nb_read;QCP_secondary;QCF_secondary;QCP_supplementary;QCF_supplementary;QCP_duplicates;QCF_duplicates;QCP_nb_mapped;QCF_nb_mapped;QCP_pct_mapped;QCF_pct_mapped;QCP_paired_in_sequencing;QCF_paired_in_sequencing;QCP_read1;QCF_read1;QCP_read2;QCF_read2;QCP_nb_properly_paired;QCF_nb_properly_paired;QCP_pct_properly_paired;QCF_pct_properly_paired;QCP_with_itself_and_mate_mapped;QCF_with_itself_and_mate_mapped;QCP_nb_singletons;QCF_nb_singletons;QCP_pct_singletons;QCF_pct_singletons;QCP_with_mate_mapped_to_a_different_chr;QCF_with_mate_mapped_to_a_different_chr;QCP_with_mate_mapped_to_a_different_chr_mapQ_over_5;QCF_with_mate_mapped_to_a_different_chr_mapQ_over_5" > {output}
        for ((i=0;i<${{#sample[*]}};++i)); do
          cond=$(echo "${{sample[i]}}" | cut -d_ -f1)
          time=$(echo "${{sample[i]}}" | cut -d_ -f2)
          qc_info=$(cat "${{qc_files[i]}}" | awk -F$'\t' '{{ print $1";"$2 }}' | paste -sd ';' - | tr -d '%')
          echo -e "${{cond}};${{time}};${{qc_info}}"
        done >> {output}
        """

# Report on nbreads in all original bam files
rule nbreads_prereport :
	input : expand("D_results_merged/bam_files_merged/{sample}.bam.nbreads", sample = SAMPLE),
	output : "D_results_merged/reports/nbreads_prereport.csv"
	params : sample = SAMPLE
	shell : """
        sample=({params.sample})
        nbreads=($(cat {input}))
        echo "condition;time;nbreads_before_downsampling" > {output}
        for ((i=0;i<${{#sample[*]}};++i)); do
          cond=$(echo "${{sample[i]}}" | cut -d_ -f1)
          time=$(echo "${{sample[i]}}" | cut -d_ -f2)
          echo "$cond;$time;${{nbreads[i]}}"
        done >> {output}
        """

# Report on nbreads before and after downsampling for all bam files
rule nbreads_report :
	input :
		before_downsampling = expand("D_results_merged/bam_files_merged/{sample}.bam.nbreads", sample = SAMPLE),
		after_downsampling = expand("D_results_merged/downsampled_bam/{sample}_downsampled.bam.nbreads", sample = SAMPLE)
	output : "D_results_merged/reports/nbreads_report.csv"
	params : sample = SAMPLE
	shell : """
        sample=({params.sample})
        nbreads_before=($(cat {input.before_downsampling}))
        nbreads_after=($(cat {input.after_downsampling}))
        echo "condition;time;nbreads_before_downsampling;nbreads_after_downsampling" > {output}
        for ((i=0;i<${{#sample[*]}};++i)); do
          cond=$(echo "${{sample[i]}}" | cut -d_ -f1)
          time=$(echo "${{sample[i]}}" | cut -d_ -f2)
          echo "$cond;$time;${{nbreads_before[i]}};${{nbreads_after[i]}}"
        done >> {output}
        """

# ATTENTION bash ne gère pas les nombres à virgule, il faut utiliser bc -l
rule nbpeaks_report :
	input :
	    before_threshold = expand("D_results_merged/macs2_output/{sample}_peaks.broadPeak", sample = SAMPLE),
		after_threshold = expand("D_results_merged/macs2_output/{sample}.threshold.broadPeak",sample = SAMPLE)
	output : "D_results_merged/reports/nbpeaks_report.csv"
	params : sample = SAMPLE
	shell : """
        sample=({params.sample})
        nbpeaks_before=($(wc -l {input.before_threshold} | awk '{{ print $1 }}'))
        nbpeaks_after=($(wc -l {input.after_threshold} | awk '{{ print $1 }}'))
        echo "condition;time;nbpeaks_before_threshold;nbpeaks_after_threshold;lost_percentage" > {output}
        for ((i=0;i<${{#sample[*]}};++i)); do
          cond=$(echo "${{sample[i]}}" | cut -d_ -f1)
          time=$(echo "${{sample[i]}}" | cut -d_ -f2)
		  pct=$(echo "scale=4; (${{nbpeaks_before[i]}}-${{nbpeaks_after[i]}})/${{nbpeaks_before[i]}}*100" | bc -l)
		  echo "$cond;$time;${{nbpeaks_before[i]}};${{nbpeaks_after[i]}};$pct"
	    done >> {output}
	"""

rule nbreads_per_peak_report :
	input : expand("D_results_merged/macs2_output/{sample}.readcount.csv", sample = SAMPLE)
	output : "D_results_merged/reports/nbreads_per_peak_report.csv"
	shell : """ awk ' FNR==1 && NR!=1 {{next}}{{print}}' {input} > {output} """  # pour enlever le header qui restait avec cat {input} > {output}

rule peak_per_chromosome_report :
	input :
		before_threshold = expand("D_results_merged/macs2_output/{sample}_peaks.df.csv", sample = SAMPLE),
		after_threshold = expand("D_results_merged/macs2_output/{sample}.threshold.df.csv", sample = SAMPLE)
	output :
		before_threshold = "D_results_merged/reports/nbpeaks_per_chromosome_report.csv",
		after_threshold = "D_results_merged/reports/nbpeaks_per_chromosome_threshold_report.csv"
	shell : """
			awk ' FNR==1 && NR!=1 {{next}}{{print}}' {input.before_threshold} > {output.before_threshold}
			awk ' FNR==1 && NR!=1 {{next}}{{print}}' {input.after_threshold} > {output.after_threshold}
			"""

# Draw QC plots from nbreads_report.csv and nb_peaks_report.csv
rule plot_reports :
	wildcard_constraints:
		format="hist_manip|line_cond|read_graph|chrom_single|chrom_multi",
		colname="[a-zA-Z_]+",
		reportname="[a-z_]+",
		extension="png|pdf"
	input :"D_results_merged/reports/{reportname}.csv"
	output : "D_results_merged/reports/{reportname}_plot_{format}-{colname}.{extension}",
	conda : "B_environments/ATACMetabo_main_env.locked.yaml"
	shell : """ Rscript C_scripts/plot_QC_variation_fusdonor.R -o {output} {wildcards.format} {input} {wildcards.colname} """
